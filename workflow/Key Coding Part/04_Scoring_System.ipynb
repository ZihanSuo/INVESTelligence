{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 1. Materiality Score Formatted",
   "id": "b17d8566f5d5821"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import json\n",
    "\n",
    "items = _input.all()\n",
    "results = []\n",
    "\n",
    "for item in items:\n",
    "    try:\n",
    "        output_data = item.get(\"json\", {}).get(\"output\", [])\n",
    "        if not output_data:\n",
    "            continue\n",
    "\n",
    "        raw_text = output_data[0][\"content\"][0][\"text\"]\n",
    "        raw = json.loads(raw_text)\n",
    "\n",
    "        meta = raw.get(\"meta\", {})\n",
    "        title = meta.get(\"title\")\n",
    "        keyword = meta.get(\"keyword\")\n",
    "        url = meta.get(\"url\")\n",
    "        pickup_count = meta.get(\"pickup_count\", 0)\n",
    "        content = raw.get(\"content\")\n",
    "        scores = raw.get(\"scores\", {})\n",
    "\n",
    "        sev = float(scores.get(\"event_severity\", {}).get(\"score\", 0))\n",
    "        prox = float(scores.get(\"market_proximity\", {}).get(\"score\", 0))\n",
    "        fwd = float(scores.get(\"forward_impact\", {}).get(\"score\", 0))\n",
    "\n",
    "        materiality_score = round((sev + prox + fwd) / 12.0, 4)\n",
    "\n",
    "        sentiment_obj = scores.get(\"sentiment_score\", {})\n",
    "        senti_score = float(sentiment_obj.get(\"score\", 0))\n",
    "\n",
    "        entities = raw.get(\"entities\", [])\n",
    "        if not isinstance(entities, list):\n",
    "            entities = []\n",
    "\n",
    "        out_json = {\n",
    "            \"title\": title,\n",
    "            \"keyword\": keyword,\n",
    "            \"url\": url,\n",
    "            \"content\": content,\n",
    "            \"pickup_count\": pickup_count,\n",
    "            \"materiality_score\": materiality_score,\n",
    "            \"event_severity_score\": sev,\n",
    "            \"market_proximity_score\": prox,\n",
    "            \"forward_impact_score\": fwd,\n",
    "            \"sentiment_score\": senti_score,\n",
    "            \"mentioned_entities\": entities\n",
    "        }\n",
    "\n",
    "        results.append({\"json\": out_json})\n",
    "\n",
    "    except Exception as e:\n",
    "        results.append({\n",
    "            \"json\": {\n",
    "                \"error\": str(e),\n",
    "                \"raw_input\": str(item)\n",
    "            }\n",
    "        })\n",
    "\n",
    "return results\n"
   ],
   "id": "4296a25a1830ecd0"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 2. Quality Score 1 (Source Credibility)\n",
   "id": "bb85493a6a0a34b2"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from urllib.parse import urlparse\n",
    "\n",
    "# --- Media Trust List Configuration ---\n",
    "source_map = {\n",
    "    # [Tier 0] Institutional & Academic Authority (0.99)\n",
    "    \"gov\": 0.99, \"nature.com\": 0.99, \"science.org\": 0.99,\n",
    "    \"worldbank.org\": 0.99, \"imf.org\": 0.99, \"iea.org\": 0.99,\n",
    "    \"who.int\": 0.99, \"un.org\": 0.99, \"bis.org\": 0.99,\n",
    "\n",
    "    # [Tier 1] Global Financial Core (0.98)\n",
    "    \"reuters.com\": 0.98, \"bloomberg.com\": 0.98,\n",
    "    \"wsj.com\": 0.98, \"ft.com\": 0.98,\n",
    "    \"nikkei.com\": 0.97, \"investors.com\": 0.96,\n",
    "\n",
    "    # [Tier 2] Industry Verticals (0.92 - 0.95)\n",
    "    \"mining.com\": 0.95,       \"oilprice.com\": 0.94,\n",
    "    \"techcrunch.com\": 0.95,   \"theinformation.com\": 0.94,\n",
    "    \"barrons.com\": 0.94,      \"spglobal.com\": 0.93,\n",
    "    \"utilitydive.com\": 0.92,  \"argusmedia.com\": 0.92,\n",
    "    \"pv-magazine.com\": 0.92,  \"hydrocarbonprocessing.com\": 0.91,\n",
    "\n",
    "    # [Tier 3] High-Quality General News (0.88 - 0.90)\n",
    "    \"nytimes.com\": 0.90,      \"economist.com\": 0.90,\n",
    "    \"apnews.com\": 0.90,       \"bbc.com\": 0.89,\n",
    "    \"washingtonpost.com\": 0.88, \"axios.com\": 0.85,\n",
    "    \"time.com\": 0.85,         \"forbes.com\": 0.85,\n",
    "\n",
    "    # [Tier 4] Aggregators & Tier 2 (0.80 - 0.85)\n",
    "    \"cnbc.com\": 0.85,         \"marketwatch.com\": 0.82,\n",
    "    \"finance.yahoo.com\": 0.80, \"businessinsider.com\": 0.78,\n",
    "    \"seekingalpha.com\": 0.75,\n",
    "\n",
    "    # [Tier 5] Low Credibility / Cautionary (< 0.6)\n",
    "    \"dailymail.co.uk\": 0.5,   \"nypost.com\": 0.5,\n",
    "    \"twitter.com\": 0.2,       \"reddit.com\": 0.2,\n",
    "    \"zerohedge.com\": 0.3,     \"thestreet.com\": 0.4,\n",
    "    \"benzinga.com\": 0.4,      \"medium.com\": 0.3\n",
    "}\n",
    "\n",
    "def get_source_score(url):\n",
    "    if not url: return 0.5\n",
    "    try:\n",
    "        # Extract clean domain\n",
    "        domain = urlparse(url).netloc.lower().replace(\"www.\", \"\")\n",
    "\n",
    "        # 1. Dynamic Rule: Gov sites\n",
    "        if domain.endswith(\".gov\"): return 0.99\n",
    "\n",
    "        # 2. Dictionary Match (Longest match first)\n",
    "        for key in sorted(source_map.keys(), key=len, reverse=True):\n",
    "            if key in domain:\n",
    "                return source_map[key]\n",
    "\n",
    "        # 3. Default for unknown sources\n",
    "        # Set to 0.5 for strict filtering in dual-stream architecture\n",
    "        return 0.5\n",
    "    except:\n",
    "        return 0.5\n",
    "\n",
    "# --- Execution Logic ---\n",
    "items = _input.all()\n",
    "results = []\n",
    "\n",
    "for item in items:\n",
    "    art = item.get(\"json\", item)\n",
    "    url = art.get(\"url\", \"\")\n",
    "\n",
    "    # Calculate score\n",
    "    score = get_source_score(url)\n",
    "\n",
    "    # Append score to JSON\n",
    "    art[\"source_credibility\"] = score\n",
    "\n",
    "    results.append({\"json\": art})\n",
    "\n",
    "return results"
   ],
   "id": "1abb29522ce76e86"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 3. Quality Score 2 (Weighted)",
   "id": "37eb22bdd7ebec7a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# ==========================================\n",
    "# Node 2: Weighted Final Scoring (Balanced)\n",
    "# Formula: Final = (Cred * 0.40) + (Topic * 0.25) + (Pickup * 0.15) + (Search * 0.20)\n",
    "# ==========================================\n",
    "\n",
    "# --- Weight Configuration ---\n",
    "W_CREDIBILITY = 0.40  # Reduced slightly to allow relevance to matter more\n",
    "W_TOPIC       = 0.25  # Strategic priority\n",
    "W_PICKUP      = 0.15  # Market Buzz\n",
    "W_SEARCH      = 0.20  # INCREASED: Penalizes off-topic articles from big media\n",
    "\n",
    "# --- Pickup Normalization ---\n",
    "MAX_PICKUP_CAP = 3.0\n",
    "\n",
    "items = _input.all()\n",
    "results = []\n",
    "\n",
    "for item in items:\n",
    "    art = item.get(\"json\", item)\n",
    "\n",
    "    # 1. Get Metrics (Strict inputs)\n",
    "\n",
    "    # A. Source Credibility\n",
    "    c_score = float(art.get(\"source_credibility\", 0.5))\n",
    "\n",
    "    # B. Topic Importance\n",
    "    t_weight = float(art.get(\"weight\", 0.8))\n",
    "    e_imp = float(art.get(\"expansion_importance\", 1.0))\n",
    "    t_score = t_weight * e_imp\n",
    "\n",
    "    # C. Pickup Score\n",
    "    raw_pickup = float(art.get(\"pickup_count\", 0))\n",
    "    p_score = min(raw_pickup / MAX_PICKUP_CAP, 1.0)\n",
    "\n",
    "    # D. Search Relevance\n",
    "    s_score = float(art.get(\"tavily_score\", 0.6))\n",
    "\n",
    "    # 2. Calculate Final Weighted Score\n",
    "    final_score = (c_score * W_CREDIBILITY) + \\\n",
    "                  (t_score * W_TOPIC) + \\\n",
    "                  (p_score * W_PICKUP) + \\\n",
    "                  (s_score * W_SEARCH)\n",
    "\n",
    "    # 3. Normalize and Round\n",
    "    final_score = round(min(final_score, 1.0), 4)\n",
    "\n",
    "    # Save derived metrics\n",
    "    art[\"qual_score\"] = final_score\n",
    "\n",
    "    # ==========================================\n",
    "    # 4. Reorder Output Columns (Strict Order)\n",
    "    # ==========================================\n",
    "\n",
    "    target_order = [\n",
    "        \"keyword\",\n",
    "        \"weight\",\n",
    "        \"expansion_importance\",\n",
    "        \"qual_score\",\n",
    "        \"title\",\n",
    "        \"url\",\n",
    "        \"content\",\n",
    "        \"source_credibility\",\n",
    "        \"tavily_score\",\n",
    "        \"pickup_count\"\n",
    "    ]\n",
    "\n",
    "    ordered_art = {}\n",
    "\n",
    "    # Ensure keyword exists\n",
    "    if \"keyword\" not in art:\n",
    "        art[\"keyword\"] = art.get(\"query\") or art.get(\"seed\") or \"unknown\"\n",
    "\n",
    "    # Insert keys in target order\n",
    "    for key in target_order:\n",
    "        if key in art:\n",
    "            ordered_art[key] = art[key]\n",
    "\n",
    "    # Append remaining keys\n",
    "    for key, val in art.items():\n",
    "        if key not in ordered_art:\n",
    "            ordered_art[key] = val\n",
    "\n",
    "    results.append({\"json\": ordered_art})\n",
    "\n",
    "return results"
   ],
   "id": "4df6b8f581fbb01e"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 4. News Score Final",
   "id": "b3f8ab0c1ee0bcbf"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import statistics\n",
    "\n",
    "items = _input.all()\n",
    "\n",
    "# Collect scores\n",
    "m_vals = [i[\"json\"].get(\"materiality_score\") for i in items if i[\"json\"].get(\"materiality_score\") is not None]\n",
    "q_vals = [i[\"json\"].get(\"qual_score\") for i in items if i[\"json\"].get(\"qual_score\") is not None]\n",
    "\n",
    "m_median = statistics.median(m_vals) if m_vals else 0.5\n",
    "q_median = statistics.median(q_vals) if q_vals else 0.5\n",
    "\n",
    "results = []\n",
    "\n",
    "for item in items:\n",
    "    original = item.get(\"json\", {})\n",
    "\n",
    "    # Copy only known fields to avoid mutation side-effects\n",
    "    j = dict(original)  # shallow copy\n",
    "\n",
    "    m_score = j.get(\"materiality_score\", m_median)\n",
    "    q_score = j.get(\"qual_score\", q_median)\n",
    "\n",
    "    final_score = float(m_score) * 0.6 + float(q_score) * 0.4\n",
    "\n",
    "    j[\"final_score_100\"] = round(final_score * 100, 2)\n",
    "\n",
    "    # preserve everything else including 'content'\n",
    "    results.append({\"json\": j})\n",
    "\n",
    "return results\n"
   ],
   "id": "1be132e9cb65aac2"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 5. Group By Keywords",
   "id": "8d699b14ffe020ed"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "items = _input.all()\n",
    "groups = {}\n",
    "\n",
    "for item in items:\n",
    "    original_json = item.get(\"json\", {})\n",
    "\n",
    "\n",
    "    content_check = original_json.get(\"content\")\n",
    "    if not content_check:\n",
    "        original_json[\"content\"] = \"[WARNING: No Content Found]\"\n",
    "\n",
    "\n",
    "    art = dict(original_json)\n",
    "\n",
    "\n",
    "    keyword = (art.get(\"keyword\") or \"unknown\").strip().lower()\n",
    "    groups.setdefault(keyword, []).append(art)\n",
    "\n",
    "output_items = []\n",
    "\n",
    "for keyword, article_list in groups.items():\n",
    "    #article_list.sort(key=lambda x: x.get(\"final_score_100\", 0), reverse=True)\n",
    "\n",
    "    output_items.append({\n",
    "        \"json\": {\n",
    "            \"keyword\": keyword,\n",
    "            \"count\": len(article_list),\n",
    "            \"articles\": article_list\n",
    "        }\n",
    "    })\n",
    "\n",
    "return output_items"
   ],
   "id": "a3b6d49d88a13719"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
